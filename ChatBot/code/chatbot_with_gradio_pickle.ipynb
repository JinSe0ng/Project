{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: pickle5\n",
      "  Building wheel for pickle5 (pyproject.toml): started\n",
      "  Building wheel for pickle5 (pyproject.toml): finished with status 'error'\n",
      "Failed to build pickle5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angsmith (c:\\Users\\seul\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hGK6LnUe-py3.11\\Lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for pickle5 (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-311\\pickle5\n",
      "      copying pickle5\\pickle.py -> build\\lib.win-amd64-cpython-311\\pickle5\n",
      "      copying pickle5\\pickletools.py -> build\\lib.win-amd64-cpython-311\\pickle5\n",
      "      copying pickle5\\__init__.py -> build\\lib.win-amd64-cpython-311\\pickle5\n",
      "      creating build\\lib.win-amd64-cpython-311\\pickle5\\test\n",
      "      copying pickle5\\test\\pickletester.py -> build\\lib.win-amd64-cpython-311\\pickle5\\test\n",
      "      copying pickle5\\test\\test_pickle.py -> build\\lib.win-amd64-cpython-311\\pickle5\\test\n",
      "      copying pickle5\\test\\test_picklebuffer.py -> build\\lib.win-amd64-cpython-311\\pickle5\\test\n",
      "      copying pickle5\\test\\__init__.py -> build\\lib.win-amd64-cpython-311\\pickle5\\test\n",
      "      running build_ext\n",
      "      building 'pickle5._pickle' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pickle5\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pickle5)\n"
     ]
    }
   ],
   "source": [
    "pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seul\\AppData\\Local\\Temp\\ipykernel_13508\\2145101619.py:172: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n",
      "C:\\Users\\seul\\AppData\\Local\\Temp\\ipykernel_13508\\2145101619.py:179: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0.2)\n",
      "C:\\Users\\seul\\AppData\\Local\\Temp\\ipykernel_13508\\2145101619.py:194: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
      "c:\\Users\\seul\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hGK6LnUe-py3.11\\Lib\\site-packages\\gradio\\components\\chatbot.py:284: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seul\\AppData\\Local\\Temp\\ipykernel_13508\\2145101619.py:208: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = retrieval_chain({\"question\": question, \"chat_history\": chat_history})\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document as LDocument\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import pymysql\n",
    "import locale\n",
    "import gradio as gr\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 설정\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import pickle\n",
    "# 피클 파일을 저장하는 함수\n",
    "def save_to_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "# 피클 파일을 로드하는 함수\n",
    "def load_from_pickle(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# MySQL 데이터베이스 연결 함수 (예시)\n",
    "def connect_to_db():\n",
    "    return pymysql.connect(\n",
    "        host='database-1.cxcqeqcc6xxo.ap-northeast-2.rds.amazonaws.com',\n",
    "        port=3306,\n",
    "        user='admin',\n",
    "        passwd='sesaclangchain',\n",
    "        db='sesaclangchain',\n",
    "        charset=\"utf8mb4\"\n",
    "    )\n",
    "\n",
    "# 온라인 강의와 오프라인 강의 정보를 가져오는 함수\n",
    "def fetch_courses():\n",
    "    connection = connect_to_db()\n",
    "    cursor = connection.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    # 온라인 강의 정보 가져오기\n",
    "    online_query = \"SELECT * FROM online_course_tbl\"\n",
    "    cursor.execute(online_query)\n",
    "    online_courses = cursor.fetchall()\n",
    "\n",
    "    # 오프라인 강의 정보 가져오기\n",
    "    offline_query = \"SELECT * FROM offline_course_tbl\"\n",
    "    cursor.execute(offline_query)\n",
    "    offline_courses = cursor.fetchall()\n",
    "\n",
    "    # 공지 \n",
    "    notice_query = \"SELECT * FROM notice_tbl\"\n",
    "    cursor.execute(notice_query)\n",
    "    notice_info = cursor.fetchall()\n",
    "\n",
    "    # qna \n",
    "    qna_query = 'SELECT * FROM qna_tbl'\n",
    "    cursor.execute(qna_query)\n",
    "    qna_info = cursor.fetchall()\n",
    "\n",
    "    # 리뷰\n",
    "    review_query = 'select * from review'\n",
    "    cursor.execute(review_query)\n",
    "    review_info = cursor.fetchall()\n",
    "\n",
    "    # 강의 이미지\n",
    "    course_image_query = 'select * from class_img2txt'\n",
    "    cursor.execute(course_image_query)\n",
    "    course_image_info = cursor.fetchall()\n",
    "\n",
    "    connection.close()\n",
    "\n",
    "    return online_courses, offline_courses, notice_info, qna_info, review_info,course_image_info\n",
    "\n",
    "# 강의 정보를 문서 형식으로 변환\n",
    "# 텍스트를 일정한 길이로 청크 분할하는 함수\n",
    "def chunk_text(text, chunk_size=500, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return text_splitter.split_text(text) if len(text) > chunk_size else [text]  # 너무 짧으면 그대로 반환\n",
    "\n",
    "# 데이터를 청크로 나누어 문서 리스트로 변환하는 함수\n",
    "def convert_to_documents(online_courses, offline_courses, notice_info, qna_info, review_info, course_image_info):\n",
    "    documents = []\n",
    "\n",
    "    # 데이터를 반복해서 처리하는 공통 함수\n",
    "    def process_and_chunk(data_list, format_func):\n",
    "        for item in data_list:\n",
    "            doc_text = format_func(item)\n",
    "            chunks = chunk_text(doc_text, chunk_size=500)\n",
    "            for chunk in chunks:\n",
    "                documents.append(LDocument(page_content=chunk))\n",
    "\n",
    "    # 각 데이터에 맞는 텍스트 포맷팅\n",
    "    process_and_chunk(online_courses, lambda course: (\n",
    "        f\"강의 제목: {course['course_title']}\\n\"\n",
    "        f\"강의 분류: {course['course_category']}\\n\"\n",
    "        f\"강의 난도: {course['course_difficulty']}\\n\"\n",
    "        f\"교육 목표: {course['course_objective']}\\n\"\n",
    "        f\"수강 대상: {course['target_audience']}\\n\"\n",
    "        f\"수강 시간: {course['class_duration']}\\n\"\n",
    "        f\"수강 기간: {course['class_period']}\\n\"\n",
    "        f\"지원 기간: {course['support_period']}\"\n",
    "    ))\n",
    "\n",
    "    process_and_chunk(offline_courses, lambda course: (\n",
    "        f\"강의 제목: {course['course_title']}\\n\"\n",
    "        f\"강의 분류: {course['course_category']}\\n\"\n",
    "        f\"교육 장소: {course['education_location']}\\n\"\n",
    "        f\"교육 목표: {course['educational_goals']}\\n\"\n",
    "        f\"수강 대상: {course['target_audience']}\\n\"\n",
    "        f\"지원 기간: {course['support_period']}\\n\"\n",
    "        f\"수강 기간: {course['class_period']}\\n\"\n",
    "        f\"지원 방법: {course['application_method']}\\n\"\n",
    "        f\"선발 절차: {course['selection_criteria']}\\n\"\n",
    "        f\"이수 기준: {course['completion_criteria']}\"\n",
    "    ))\n",
    "\n",
    "    process_and_chunk(notice_info, lambda notice: (\n",
    "        f\"공지 제목: {notice['notice_title']}\\n\"\n",
    "        f\"공지 날짜: {notice['notice_date']}\\n\"\n",
    "        f\"공지 내용: {notice['notice_content']}\"\n",
    "    ))\n",
    "\n",
    "    process_and_chunk(qna_info, lambda qna: (\n",
    "        f\"Q: {qna['question_title']}\\n\"\n",
    "        f\"질문: {qna['question_content']}\\n\"\n",
    "        f\"A: {qna['answer_content']}\"\n",
    "    ))\n",
    "\n",
    "    process_and_chunk(review_info, lambda review: (\n",
    "        f\"강의 제목: {review['course_title']}\\n\"\n",
    "        f\"강의 별점: {review['rate']}\\n\"\n",
    "        f\"작성 날짜: {review['r_date']}\\n\"\n",
    "        f\"리뷰 내용: {review['content']}\\n\"\n",
    "        f\"리뷰 요약: {review['summarized_content']}\"\n",
    "    ))\n",
    "\n",
    "    process_and_chunk(course_image_info, lambda image: (\n",
    "        f\"강의 제목: {image['course_title']}\\n\"\n",
    "        f\"강의 이미지 설명: {image['image_txt']}\"\n",
    "    ))\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 텍스트를 일정한 길이로 청크 분할\n",
    "def chunk_text(text, chunk_size=500, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "# 벡터 스토어 생성 (FAISS 사용)\n",
    "def create_vector_store(documents):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_documents(documents, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "# 질문과 관련된 강의를 검색하고 답변을 생성하는 챗봇\n",
    "def create_chatbot(vector_store, user_prompt, system_prompt):\n",
    "    # OpenAI LLM 설정\n",
    "    llm = OpenAI(temperature=0.2)\n",
    "\n",
    "    # 프롬프트 템플릿 생성\n",
    "    prompt_template = \"\"\"\n",
    "    시스템 프롬프트: {system_message}\n",
    "    사용자 프롬프트: {user_message}\n",
    "    사용자의 질문: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"system_message\", \"user_message\", \"question\"],\n",
    "        template=prompt_template\n",
    "    )\n",
    "\n",
    "    # PromptTemplate을 사용하여 LLM을 설정\n",
    "    chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "    # ConversationalRetrievalChain 생성\n",
    "    retrieval_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=chat_model,\n",
    "        retriever=vector_store.as_retriever(),\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "    return retrieval_chain\n",
    "\n",
    "# 사용자 질문에 대한 답변을 생성하는 함수\n",
    "def get_answer(question, retrieval_chain, chat_history):\n",
    "    try:\n",
    "        result = retrieval_chain({\"question\": question, \"chat_history\": chat_history})\n",
    "\n",
    "        # 검색된 문서가 너무 많을 경우 일부만 사용하도록 설정\n",
    "        source_documents = result.get('source_documents', [])\n",
    "        max_docs = 5  # 최대 반환할 문서 개수 제한\n",
    "        source_documents = source_documents[:max_docs]  # 최대 개수만큼 자르기\n",
    "\n",
    "        answer = result.get('answer', '죄송합니다. 답변을 생성하는 중 오류가 발생했습니다. 🙏')\n",
    "\n",
    "        return answer, source_documents\n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 기본 안내 메시지 반환\n",
    "        error_message = f\"죄송합니다. 답변을 처리하는 중 오류가 발생했습니다. 😢\\n오류 내용: {str(e)}\"\n",
    "        return error_message, []\n",
    "\n",
    "# main 함수\n",
    "def main():\n",
    "    # 시스템 로케일을 'ko_KR.UTF-8'로 설정하여 한글 깨짐을 방지\n",
    "    \n",
    "    pickle_filename = \"all_documents.pkl\"\n",
    "    # 1. 피클 파일이 있으면 로드하고, 없으면 데이터베이스에서 데이터를 가져와서 문서 생성\n",
    "    all_documents = load_from_pickle(pickle_filename)\n",
    "\n",
    "    \n",
    "    locale.setlocale(locale.LC_ALL, 'ko_KR.UTF-8')\n",
    "    if all_documents is None:\n",
    "        # 강의 데이터 가져오기\n",
    "        online_courses, offline_courses, notice_info, qna_info, review_info,course_image_info = fetch_courses()\n",
    "\n",
    "        # 강의 정보를 문서로 변환\n",
    "        documents = convert_to_documents(online_courses, offline_courses, notice_info, qna_info, review_info,course_image_info)\n",
    "\n",
    "        all_documents = []\n",
    "        all_documents.extend(documents)\n",
    "\n",
    "        save_to_pickle(all_documents, pickle_filename)\n",
    "    else:\n",
    "        documents = all_documents\n",
    "\n",
    "    # 벡터 스토어 생성\n",
    "    vector_store = create_vector_store(documents)\n",
    "\n",
    "    # 사용자 프롬프트와 시스템 프롬프트 정의\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 싹가능팀에서 만든 한국의 도시 서울에서 제공하는 취업 프로그램인 청년취업사관학교의 챗봇 '싹톡'입니다. \n",
    "    당신은 청년사관학교의 강의,공지사항에 관한 정보를 모두 갖고 있는 유능한 관리자입니다.\n",
    "    대답할 때 반드시 적절한 이모지를 포함하세요! 🎉  \n",
    "    예를 들면:  \n",
    "    \"오늘 날씨는 맑아요! ☀️\"  \n",
    "    \"좋은 하루 보내세요! 😃\"  \n",
    "\n",
    "    \"\"\"\n",
    "    user_prompt = \"\"\"\n",
    "    당신에게 주어진 정보는 온라인/오프라인 강의 정보와 강의 리뷰, 질문답하기, 공지사항 등 청년사관학교와 관련된 데이터를 가지고 있으며, 그 외 질문에는 답변이 어렵다고 말하거나 정확한 질문을 요청하세요.\n",
    "    당신은 질문에 대한 답변을 할때 다음의 원칙을 따릅니다.\n",
    "    1. 오탈자 및 불필요한 기호 수정\n",
    "    - 잘못된 문법, 의미 없는 특수문자, 깨진 문자(예: @, #, %) 등을 제거 혹은 수정합니다.\n",
    "    2. 가독성 향상\n",
    "    - 문장을 논리적으로 정리하여 가독성을 높이고, 관련된 내용을 묶어서 단락을 구성합니다.\n",
    "    3. 목차 및 섹션 정리\n",
    "    - 제목과 본문을 명확하게 구분합니다.\n",
    "    4. 수업 관련 답변시 예시들기\n",
    "    - 수업과 관련한 질문이 들어왔을시, 당신이 가지고 있는 정보를 최대한 활용한 예시를 같이 들어주세요.\n",
    "    5. 다른 내용 참고하라고 말하지 않기.\n",
    "    - 당신 외에 다른 담당자는 존재하지 않습니다. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # 챗봇 생성\n",
    "    retrieval_chain = create_chatbot(vector_store, user_prompt, system_prompt)\n",
    "\n",
    "    # 대화 기록 초기화\n",
    "    chat_history = []\n",
    "\n",
    "    # Gradio 인터페이스 생성\n",
    "    def chat_interface(user_input):\n",
    "        try:\n",
    "            # 답변 생성\n",
    "            answer, _ = get_answer(user_input, retrieval_chain, chat_history)\n",
    "\n",
    "            # 대화 기록에 (사용자 질문, 챗봇 답변) 추가\n",
    "            chat_history.append((user_input, answer))\n",
    "\n",
    "            # 챗봇의 응답을 (질문, 응답) 형태로 반환\n",
    "            return [(user_input, answer)]\n",
    "        except Exception as e:\n",
    "            return [(user_input, f\"더 명확하게 질문을 해주세요😃\")]\n",
    "\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"\"\"\n",
    "        <div style=\"text-align: center;\">\n",
    "            <img src=\"https://sesac.seoul.kr/static/common/images/www/common/logo.png\" alt=\"logo\" style=\"display: inline; width: 25px;\"/>\n",
    "            <h1 style=\"display:inline; color: #6FC274;\">SESAC</h1>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        chatbot = gr.Chatbot()\n",
    "        user_input = gr.Textbox(label=\"질문을 입력하세요\", placeholder=\"질문을 입력하세요\", interactive=True )\n",
    "        user_input.submit(chat_interface, inputs=user_input, outputs=chatbot)\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "# 프로그램 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-hGK6LnUe-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
